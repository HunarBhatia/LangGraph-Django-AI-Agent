{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa93544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup \n",
    "setup.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e082b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai.agents import get_document_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c735a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent =get_document_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7739f373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tags': [], 'metadata': {'thread_id': '65def037-61ac-4e58-a31c-6203a8b14d0a', 'langgraph_step': 2, 'langgraph_node': 'tools', 'langgraph_triggers': ('__pregel_push',), 'langgraph_path': ('__pregel_push', 0, False), 'langgraph_checkpoint_ns': 'tools:b38c9a56-9782-4192-de4a-0af35eef15d9', 'checkpoint_ns': 'tools:b38c9a56-9782-4192-de4a-0af35eef15d9'}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x000001BB7A8A2E10>, 'recursion_limit': 10000, 'configurable': {'thread_id': '65def037-61ac-4e58-a31c-6203a8b14d0a', '__pregel_runtime': Runtime(context=None, store=None, stream_writer=<function Pregel.stream.<locals>.stream_writer at 0x000001BB79BF6020>, previous=None), '__pregel_task_id': 'b38c9a56-9782-4192-de4a-0af35eef15d9', '__pregel_send': <built-in method extend of collections.deque object at 0x000001BB7A5DB880>, '__pregel_read': functools.partial(<function local_read at 0x000001BB79779260>, PregelScratchpad(step=2, stop=10000, call_counter=<langgraph.pregel._algo.LazyAtomicCounter object at 0x000001BB7A7EEFE0>, interrupt_counter=<langgraph.pregel._algo.LazyAtomicCounter object at 0x000001BB7A7EEA10>, get_null_resume=<function _scratchpad.<locals>.get_null_resume at 0x000001BB79BF5F80>, resume=[], subgraph_counter=<langgraph.pregel._algo.LazyAtomicCounter object at 0x000001BB7A7ED510>), {'messages': <langgraph.channels.binop.BinaryOperatorAggregate object at 0x000001BB7A841E80>, 'jump_to': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x000001BB7A841500>, 'structured_response': <langgraph.channels.last_value.LastValue object at 0x000001BB7A842200>, '__start__': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x000001BB7A8421C0>, '__pregel_tasks': <langgraph.channels.topic.Topic object at 0x000001BB7A842100>, 'branch:to:model': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x000001BB7A841AC0>, 'branch:to:tools': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x000001BB7A841800>}, {}, PregelTaskWrites(path=('__pregel_push', 0, False), name='tools', writes=deque([]), triggers=('__pregel_push',))), '__pregel_checkpointer': None, 'checkpoint_map': {'': '1f0e5a70-82b7-6861-8001-1a1c5e2f2759'}, 'checkpoint_id': None, 'checkpoint_ns': 'tools:b38c9a56-9782-4192-de4a-0af35eef15d9', '__pregel_scratchpad': PregelScratchpad(step=2, stop=10000, call_counter=<langgraph.pregel._algo.LazyAtomicCounter object at 0x000001BB7A7EEFE0>, interrupt_counter=<langgraph.pregel._algo.LazyAtomicCounter object at 0x000001BB7A7EEA10>, get_null_resume=<function _scratchpad.<locals>.get_null_resume at 0x000001BB79BF5F80>, resume=[], subgraph_counter=<langgraph.pregel._algo.LazyAtomicCounter object at 0x000001BB7A7ED510>), '__pregel_call': functools.partial(<function _call at 0x000001BB797AB100>, <weakref at 0x000001BB7A871260; to 'PregelExecutableTask' at 0x000001BB7A813AD0>, retry_policy=None, futures=<weakref at 0x000001BB7A871210; to 'FuturesDict' at 0x000001BB7A871040>, schedule_task=<bound method SyncPregelLoop.accept_push of <langgraph.pregel._loop.SyncPregelLoop object at 0x000001BB7A8695E0>>, submit=<weakref at 0x000001BB7A7AF7D0; to 'BackgroundExecutor' at 0x000001BB7A093020>)}}\n",
      "You have two recent documents:\n",
      "\n",
      "1. \"Test\"\n",
      "2. \"Hello WORLD\"\n",
      "\n",
      "The document with the bigger title is \"Hello WORLD\".\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "# Configure with thread_id for conversation memory\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "# Invoke the agent\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what are my recent documents? Also, tell me the one with the bigger title\"}]},\n",
    "    config\n",
    ")\n",
    "\n",
    "# Access the response\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eff383df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='what are my recent documents? Also, tell me the one with the bigger title' additional_kwargs={} response_metadata={} id='ecfaa2f5-efb4-4bd0-8772-3782625bc4bc' what are my recent documents? Also, tell me the one with the bigger title\n",
      "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 87, 'total_tokens': 97, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a0e9480a2f', 'id': 'chatcmpl-CsY2aK9tBNTQbxKBFuUf9NbYf3UQT', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--019b705b-7215-7603-8115-c7c9c20da111-0' tool_calls=[{'name': 'list_documents', 'args': {}, 'id': 'call_M0Pu5PHfZU3YyCo8qKWWijfB', 'type': 'tool_call'}] usage_metadata={'input_tokens': 87, 'output_tokens': 10, 'total_tokens': 97, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}} \n",
      "content=\"[{'id': <built-in function id>, 'title': 'Test'}, {'id': <built-in function id>, 'title': 'Hello WORLD'}]\" name='list_documents' id='38544783-66fd-458f-ac43-e5a98e6c7828' tool_call_id='call_M0Pu5PHfZU3YyCo8qKWWijfB' [{'id': <built-in function id>, 'title': 'Test'}, {'id': <built-in function id>, 'title': 'Hello WORLD'}]\n",
      "content='You have two recent documents:\\n\\n1. \"Test\"\\n2. \"Hello WORLD\"\\n\\nThe document with the bigger title is \"Hello WORLD\".' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 138, 'total_tokens': 167, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a0e9480a2f', 'id': 'chatcmpl-CsY2cAOGkFE7vJmHJoVl4PdMBDEBw', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b705b-75e0-7ad2-b258-ba4595b9a597-0' usage_metadata={'input_tokens': 138, 'output_tokens': 29, 'total_tokens': 167, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}} You have two recent documents:\n",
      "\n",
      "1. \"Test\"\n",
      "2. \"Hello WORLD\"\n",
      "\n",
      "The document with the bigger title is \"Hello WORLD\".\n"
     ]
    }
   ],
   "source": [
    "# To get your search history\n",
    "for i in response['messages']:\n",
    "    print(i , i.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
